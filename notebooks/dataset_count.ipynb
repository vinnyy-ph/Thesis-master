{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df6f4c6b",
   "metadata": {},
   "source": [
    "# Dataset File Counter\n",
    "\n",
    "This notebook analyzes the structure of image datasets organized in the standard format:\n",
    "- Each dataset has train/test/val splits\n",
    "- Each split has real (0) and fake (1) image subfolders\n",
    "\n",
    "The optimized version includes:\n",
    "1. Performance timing\n",
    "2. Progress indicators\n",
    "3. Consolidated results display\n",
    "4. Error handling for missing folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82648022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing dataset: StyleGAN2_256\n",
      "Full path: /home/vincent/Thesis-master/dataset/StyleGAN2_256\n",
      "--------------------------------------------------\n",
      "\n",
      "TRAIN Split (StyleGAN2_256/train):\n",
      "  Real images (0): 35100\n",
      "  Fake images (1): 42356\n",
      "  Total: 77456\n",
      "\n",
      "VAL Split (StyleGAN2_256/val):\n",
      "  Real images (0): 3900\n",
      "  Fake images (1): 3900\n",
      "  Total: 7800\n",
      "\n",
      "TEST Split (StyleGAN2_256/test):\n",
      "  Real images (0): 30000\n",
      "  Fake images (1): 30000\n",
      "  Total: 60000\n",
      "\n",
      "OVERALL TOTALS FOR DATASET: StyleGAN2_256\n",
      "Total real images (0): 69000\n",
      "Total fake images (1): 76256\n",
      "Total images in dataset: 145256\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "def count_files_in_folder(folder_path):\n",
    "    \"\"\"Count the number of files in a folder.\"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder {folder_path} does not exist.\")\n",
    "        return 0\n",
    "    \n",
    "    # Get the list of files in the folder\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    return len(files)\n",
    "\n",
    "# Define the main folder path\n",
    "data_folder = \"/home/vincent/Thesis-master/dataset/StyleGAN2_256\"\n",
    "folder_name = osp.basename(data_folder)\n",
    "\n",
    "# Print the dataset folder being analyzed\n",
    "print(f\"Analyzing dataset: {folder_name}\")\n",
    "print(f\"Full path: {data_folder}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Dataset splits\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# Results dictionary to store counts\n",
    "results = {}\n",
    "total_real = 0\n",
    "total_fake = 0\n",
    "\n",
    "# Count files in each split\n",
    "for split in splits:\n",
    "    split_path = os.path.join(data_folder, split)\n",
    "    \n",
    "    if not os.path.exists(split_path):\n",
    "        print(f\"Split folder {split_path} does not exist.\")\n",
    "        continue\n",
    "    \n",
    "    # Count real images (0)\n",
    "    real_path = os.path.join(split_path, \"0\")\n",
    "    real_count = count_files_in_folder(real_path)\n",
    "    total_real += real_count\n",
    "    \n",
    "    # Count fake images (1)\n",
    "    fake_path = os.path.join(split_path, \"1\")\n",
    "    fake_count = count_files_in_folder(fake_path)\n",
    "    total_fake += fake_count\n",
    "    \n",
    "    # Store results for this split\n",
    "    results[split] = {\n",
    "        \"real\": real_count,\n",
    "        \"fake\": fake_count,\n",
    "        \"total\": real_count + fake_count\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{split.upper()} Split ({folder_name}/{split}):\")\n",
    "    print(f\"  Real images (0): {real_count}\")\n",
    "    print(f\"  Fake images (1): {fake_count}\")\n",
    "    print(f\"  Total: {real_count + fake_count}\")\n",
    "\n",
    "# Print overall totals\n",
    "print(\"\\nOVERALL TOTALS FOR DATASET:\", folder_name)\n",
    "print(f\"Total real images (0): {total_real}\")\n",
    "print(f\"Total fake images (1): {total_fake}\")\n",
    "print(f\"Total images in dataset: {total_real + total_fake}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abe3f6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 dataset folders: ['StarGAN_128', 'StyleGAN_256', 'StyleGAN2_256', 'DEFACTO_256', 'FLUX1_256']\n",
      "\n",
      "============================================================\n",
      "ANALYZING DATASET: StarGAN_128\n",
      "Full path: /home/vincent/Thesis-master/dataset\\StarGAN_128\n",
      "============================================================\n",
      "\n",
      "TRAIN Split (StarGAN_128/train):\n",
      "  Real images (0): 137239\n",
      "  Fake images (1): 137239\n",
      "  Total: 274478\n",
      "\n",
      "VAL Split (StarGAN_128/val):\n",
      "  Real images (0): 15260\n",
      "  Fake images (1): 15260\n",
      "  Total: 30520\n",
      "\n",
      "TEST Split (StarGAN_128/test):\n",
      "  Real images (0): 50000\n",
      "  Fake images (1): 50000\n",
      "  Total: 100000\n",
      "\n",
      "TOTALS FOR DATASET: StarGAN_128\n",
      "Total real images (0): 202499\n",
      "Total fake images (1): 202499\n",
      "Total images in dataset: 404998\n",
      "\n",
      "============================================================\n",
      "ANALYZING DATASET: StyleGAN_256\n",
      "Full path: /home/vincent/Thesis-master/dataset\\StyleGAN_256\n",
      "============================================================\n",
      "\n",
      "TRAIN Split (StyleGAN_256/train):\n",
      "  Real images (0): 35099\n",
      "  Fake images (1): 33739\n",
      "  Total: 68838\n",
      "\n",
      "VAL Split (StyleGAN_256/val):\n",
      "  Real images (0): 3900\n",
      "  Fake images (1): 3900\n",
      "  Total: 7800\n",
      "\n",
      "TEST Split (StyleGAN_256/test):\n",
      "  Real images (0): 30000\n",
      "  Fake images (1): 30000\n",
      "  Total: 60000\n",
      "\n",
      "TOTALS FOR DATASET: StyleGAN_256\n",
      "Total real images (0): 68999\n",
      "Total fake images (1): 67639\n",
      "Total images in dataset: 136638\n",
      "\n",
      "============================================================\n",
      "ANALYZING DATASET: StyleGAN2_256\n",
      "Full path: /home/vincent/Thesis-master/dataset\\StyleGAN2_256\n",
      "============================================================\n",
      "\n",
      "TRAIN Split (StyleGAN2_256/train):\n",
      "  Real images (0): 35100\n",
      "  Fake images (1): 42356\n",
      "  Total: 77456\n",
      "\n",
      "VAL Split (StyleGAN2_256/val):\n",
      "  Real images (0): 3900\n",
      "  Fake images (1): 3900\n",
      "  Total: 7800\n",
      "\n",
      "TEST Split (StyleGAN2_256/test):\n",
      "  Real images (0): 30000\n",
      "  Fake images (1): 30000\n",
      "  Total: 60000\n",
      "\n",
      "TOTALS FOR DATASET: StyleGAN2_256\n",
      "Total real images (0): 69000\n",
      "Total fake images (1): 76256\n",
      "Total images in dataset: 145256\n",
      "\n",
      "============================================================\n",
      "ANALYZING DATASET: DEFACTO_256\n",
      "Full path: /home/vincent/Thesis-master/dataset\\DEFACTO_256\n",
      "============================================================\n",
      "\n",
      "TRAIN Split (DEFACTO_256/train):\n",
      "  Real images (0): 36100\n",
      "  Fake images (1): 39680\n",
      "  Total: 75780\n",
      "Split folder /home/vincent/Thesis-master/dataset\\DEFACTO_256\\val does not exist.\n",
      "\n",
      "TEST Split (DEFACTO_256/test):\n",
      "  Real images (0): 30000\n",
      "  Fake images (1): 30000\n",
      "  Total: 60000\n",
      "\n",
      "TOTALS FOR DATASET: DEFACTO_256\n",
      "Total real images (0): 66100\n",
      "Total fake images (1): 69680\n",
      "Total images in dataset: 135780\n",
      "\n",
      "============================================================\n",
      "ANALYZING DATASET: FLUX1_256\n",
      "Full path: /home/vincent/Thesis-master/dataset\\FLUX1_256\n",
      "============================================================\n",
      "\n",
      "TRAIN Split (FLUX1_256/train):\n",
      "  Real images (0): 36100\n",
      "  Fake images (1): 34616\n",
      "  Total: 70716\n",
      "\n",
      "VAL Split (FLUX1_256/val):\n",
      "  Real images (0): 3900\n",
      "  Fake images (1): 3900\n",
      "  Total: 7800\n",
      "\n",
      "TEST Split (FLUX1_256/test):\n",
      "  Real images (0): 30000\n",
      "  Fake images (1): 30000\n",
      "  Total: 60000\n",
      "\n",
      "TOTALS FOR DATASET: FLUX1_256\n",
      "Total real images (0): 70000\n",
      "Total fake images (1): 68516\n",
      "Total images in dataset: 138516\n",
      "\n",
      "============================================================\n",
      "GRAND TOTALS ACROSS ALL DATASETS\n",
      "Total real images (0): 476598\n",
      "Total fake images (1): 484590\n",
      "Total images: 961188\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze multiple dataset folders\n",
    "def analyze_all_datasets(base_path=\"/home/vincent/Thesis-master/dataset\"):\n",
    "    \"\"\"\n",
    "    Analyze all dataset folders in the base path\n",
    "    \"\"\"\n",
    "    # Find all directories in the base path\n",
    "    dataset_folders = [f for f in os.listdir(base_path) \n",
    "                      if os.path.isdir(os.path.join(base_path, f))]\n",
    "    \n",
    "    print(f\"Found {len(dataset_folders)} dataset folders: {dataset_folders}\")\n",
    "    \n",
    "    grand_total_real = 0\n",
    "    grand_total_fake = 0\n",
    "    \n",
    "    for dataset in dataset_folders:\n",
    "        data_folder = os.path.join(base_path, dataset)\n",
    "        folder_name = osp.basename(data_folder)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"ANALYZING DATASET: {folder_name}\")\n",
    "        print(f\"Full path: {data_folder}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Dataset splits\n",
    "        splits = [\"train\", \"val\", \"test\"]\n",
    "        \n",
    "        # Results dictionary to store counts\n",
    "        dataset_real = 0\n",
    "        dataset_fake = 0\n",
    "        \n",
    "        # Count files in each split\n",
    "        for split in splits:\n",
    "            split_path = os.path.join(data_folder, split)\n",
    "            \n",
    "            if not os.path.exists(split_path):\n",
    "                print(f\"Split folder {split_path} does not exist.\")\n",
    "                continue\n",
    "            \n",
    "            # Count real images (0)\n",
    "            real_path = os.path.join(split_path, \"0\")\n",
    "            real_count = count_files_in_folder(real_path)\n",
    "            dataset_real += real_count\n",
    "            \n",
    "            # Count fake images (1)\n",
    "            fake_path = os.path.join(split_path, \"1\")\n",
    "            fake_count = count_files_in_folder(fake_path)\n",
    "            dataset_fake += fake_count\n",
    "            \n",
    "            print(f\"\\n{split.upper()} Split ({folder_name}/{split}):\")\n",
    "            print(f\"  Real images (0): {real_count}\")\n",
    "            print(f\"  Fake images (1): {fake_count}\")\n",
    "            print(f\"  Total: {real_count + fake_count}\")\n",
    "        \n",
    "        # Print dataset totals\n",
    "        print(f\"\\nTOTALS FOR DATASET: {folder_name}\")\n",
    "        print(f\"Total real images (0): {dataset_real}\")\n",
    "        print(f\"Total fake images (1): {dataset_fake}\")\n",
    "        print(f\"Total images in dataset: {dataset_real + dataset_fake}\")\n",
    "        \n",
    "        grand_total_real += dataset_real\n",
    "        grand_total_fake += dataset_fake\n",
    "    \n",
    "    # Print grand totals\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GRAND TOTALS ACROSS ALL DATASETS\")\n",
    "    print(f\"Total real images (0): {grand_total_real}\")\n",
    "    print(f\"Total fake images (1): {grand_total_fake}\")\n",
    "    print(f\"Total images: {grand_total_real + grand_total_fake}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Uncomment to run analysis on all datasets\n",
    "analyze_all_datasets()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ede1a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 dataset categories: ['Handcrafted', 'GAN', 'Diffusion']\n",
      "\n",
      "============================================================\n",
      "ANALYZING CATEGORY: Handcrafted\n",
      "============================================================\n",
      "Found 1 datasets in Handcrafted: ['DEFACTO_256']\n",
      "\n",
      "------------------------------------------------------------\n",
      "ANALYZING DATASET: Handcrafted/DEFACTO_256\n",
      "Full path: /home/vincent/Thesis-master/dataset\\Handcrafted\\DEFACTO_256\n",
      "------------------------------------------------------------\n",
      "  TRAIN Split: Real: 36100, Fake: 39680, Total: 75780\n",
      "  TEST Split: Real: 30000, Fake: 30000, Total: 60000\n",
      "  VALIDATION Split: Real: 3900, Fake: 9920, Total: 13820\n",
      "\n",
      "TOTALS FOR DATASET Handcrafted/DEFACTO_256:\n",
      "  Real images (0): 70000\n",
      "  Fake images (1): 79600\n",
      "  Total images: 149600\n",
      "  Processing time: 171.33 seconds\n",
      "\n",
      "------------------------------------------------------------\n",
      "TOTALS FOR CATEGORY: Handcrafted\n",
      "  Real images (0): 70000\n",
      "  Fake images (1): 79600\n",
      "  Total images: 149600\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "ANALYZING CATEGORY: GAN\n",
      "============================================================\n",
      "Found 3 datasets in GAN: ['StarGAN_128', 'StyleGAN_256', 'StyleGAN2_256']\n",
      "\n",
      "------------------------------------------------------------\n",
      "ANALYZING DATASET: GAN/StarGAN_128\n",
      "Full path: /home/vincent/Thesis-master/dataset\\GAN\\StarGAN_128\n",
      "------------------------------------------------------------\n",
      "  TRAIN Split: Real: 137239, Fake: 137239, Total: 274478\n",
      "  VAL Split: Real: 15260, Fake: 15260, Total: 30520\n",
      "  TEST Split: Real: 50000, Fake: 50000, Total: 100000\n",
      "\n",
      "TOTALS FOR DATASET GAN/StarGAN_128:\n",
      "  Real images (0): 202499\n",
      "  Fake images (1): 202499\n",
      "  Total images: 404998\n",
      "  Processing time: 468.24 seconds\n",
      "\n",
      "------------------------------------------------------------\n",
      "ANALYZING DATASET: GAN/StyleGAN_256\n",
      "Full path: /home/vincent/Thesis-master/dataset\\GAN\\StyleGAN_256\n",
      "------------------------------------------------------------\n",
      "  TRAIN Split: Real: 35099, Fake: 33739, Total: 68838\n",
      "  VAL Split: Real: 3900, Fake: 3900, Total: 7800\n",
      "  TEST Split: Real: 30000, Fake: 30000, Total: 60000\n",
      "\n",
      "TOTALS FOR DATASET GAN/StyleGAN_256:\n",
      "  Real images (0): 68999\n",
      "  Fake images (1): 67639\n",
      "  Total images: 136638\n",
      "  Processing time: 157.10 seconds\n",
      "\n",
      "------------------------------------------------------------\n",
      "ANALYZING DATASET: GAN/StyleGAN2_256\n",
      "Full path: /home/vincent/Thesis-master/dataset\\GAN\\StyleGAN2_256\n",
      "------------------------------------------------------------\n",
      "  TRAIN Split: Real: 35100, Fake: 42356, Total: 77456\n",
      "  VAL Split: Real: 3900, Fake: 3900, Total: 7800\n",
      "  TEST Split: Real: 30000, Fake: 30000, Total: 60000\n",
      "\n",
      "TOTALS FOR DATASET GAN/StyleGAN2_256:\n",
      "  Real images (0): 69000\n",
      "  Fake images (1): 76256\n",
      "  Total images: 145256\n",
      "  Processing time: 167.13 seconds\n",
      "\n",
      "------------------------------------------------------------\n",
      "TOTALS FOR CATEGORY: GAN\n",
      "  Real images (0): 340498\n",
      "  Fake images (1): 346394\n",
      "  Total images: 686892\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "ANALYZING CATEGORY: Diffusion\n",
      "============================================================\n",
      "Found 2 datasets in Diffusion: ['StableDIffusion_256', 'FLUX1_256']\n",
      "\n",
      "------------------------------------------------------------\n",
      "ANALYZING DATASET: Diffusion/StableDIffusion_256\n",
      "Full path: /home/vincent/Thesis-master/dataset\\Diffusion\\StableDIffusion_256\n",
      "------------------------------------------------------------\n",
      "  TRAIN Split: Real: 49000, Fake: 23100, Total: 72100\n",
      "  VAL Split: Real: 7000, Fake: 3300, Total: 10300\n",
      "  TEST Split: Real: 14000, Fake: 6600, Total: 20600\n",
      "\n",
      "TOTALS FOR DATASET Diffusion/StableDIffusion_256:\n",
      "  Real images (0): 70000\n",
      "  Fake images (1): 33000\n",
      "  Total images: 103000\n",
      "  Processing time: 119.83 seconds\n",
      "\n",
      "------------------------------------------------------------\n",
      "ANALYZING DATASET: Diffusion/FLUX1_256\n",
      "Full path: /home/vincent/Thesis-master/dataset\\Diffusion\\FLUX1_256\n",
      "------------------------------------------------------------\n",
      "  TRAIN Split: Real: 36100, Fake: 34616, Total: 70716\n",
      "  VAL Split: Real: 3900, Fake: 3900, Total: 7800\n",
      "  TEST Split: Real: 30000, Fake: 30000, Total: 60000\n",
      "\n",
      "TOTALS FOR DATASET Diffusion/FLUX1_256:\n",
      "  Real images (0): 70000\n",
      "  Fake images (1): 68516\n",
      "  Total images: 138516\n",
      "  Processing time: 160.14 seconds\n",
      "\n",
      "------------------------------------------------------------\n",
      "TOTALS FOR CATEGORY: Diffusion\n",
      "  Real images (0): 140000\n",
      "  Fake images (1): 101516\n",
      "  Total images: 241516\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "GRAND TOTALS ACROSS ALL DATASETS\n",
      "Total real images (0): 550498\n",
      "Total fake images (1): 527510\n",
      "Total images: 1078008\n",
      "Total processing time: 1243.79 seconds\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "def analyze_nested_datasets(base_path=\"/home/vincent/Thesis-master/dataset\"):\n",
    "    \"\"\"\n",
    "    Analyze datasets with nested directory structure:\n",
    "    - base_path/\n",
    "      - Diffusion/\n",
    "        - FLUX1_256/\n",
    "        - StableDiffusion_256/\n",
    "      - GAN/\n",
    "        - StarGAN_128/\n",
    "        - StyleGAN_256/\n",
    "        - StyleGAN2_256/\n",
    "      - Handcrafted/\n",
    "        - DEFACTO_256/\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Find all category directories in the base path\n",
    "    category_folders = [f for f in os.listdir(base_path) \n",
    "                      if os.path.isdir(os.path.join(base_path, f))]\n",
    "    \n",
    "    print(f\"Found {len(category_folders)} dataset categories: {category_folders}\")\n",
    "    \n",
    "    # Store results for visualization later\n",
    "    all_results = defaultdict(dict)\n",
    "    grand_total_real = 0\n",
    "    grand_total_fake = 0\n",
    "    \n",
    "    # For each category (Diffusion, GAN, Handcrafted)\n",
    "    for category in category_folders:\n",
    "        category_path = os.path.join(base_path, category)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ANALYZING CATEGORY: {category}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Find all dataset folders within this category\n",
    "        dataset_folders = [f for f in os.listdir(category_path) \n",
    "                          if os.path.isdir(os.path.join(category_path, f))]\n",
    "        \n",
    "        print(f\"Found {len(dataset_folders)} datasets in {category}: {dataset_folders}\")\n",
    "        \n",
    "        category_real = 0\n",
    "        category_fake = 0\n",
    "        \n",
    "        # For each dataset within the category\n",
    "        for dataset in dataset_folders:\n",
    "            dataset_start_time = time.time()\n",
    "            data_folder = os.path.join(category_path, dataset)\n",
    "            folder_name = osp.basename(data_folder)\n",
    "            full_name = f\"{category}/{folder_name}\"\n",
    "            \n",
    "            print(f\"\\n{'-'*60}\")\n",
    "            print(f\"ANALYZING DATASET: {full_name}\")\n",
    "            print(f\"Full path: {data_folder}\")\n",
    "            print(f\"{'-'*60}\")\n",
    "            \n",
    "            # Dataset splits\n",
    "            splits = [\"train\", \"val\", \"test\", \"validation\"]  # Added \"validation\" as it appears in some datasets\n",
    "            \n",
    "            # Results for this dataset\n",
    "            dataset_real = 0\n",
    "            dataset_fake = 0\n",
    "            dataset_results = {}\n",
    "            \n",
    "            # Count files in each split\n",
    "            for split in splits:\n",
    "                split_path = os.path.join(data_folder, split)\n",
    "                \n",
    "                if not os.path.exists(split_path):\n",
    "                    # Skip without printing for expected missing splits\n",
    "                    continue\n",
    "                \n",
    "                # Instead of calling count_files_in_folder multiple times,\n",
    "                # do a single directory scan for efficiency\n",
    "                real_count = 0\n",
    "                fake_count = 0\n",
    "                \n",
    "                # Count real images (0)\n",
    "                real_path = os.path.join(split_path, \"0\")\n",
    "                if os.path.exists(real_path):\n",
    "                    real_count = len([f for f in os.listdir(real_path) \n",
    "                                     if os.path.isfile(os.path.join(real_path, f))])\n",
    "                \n",
    "                # Count fake images (1)\n",
    "                fake_path = os.path.join(split_path, \"1\")\n",
    "                if os.path.exists(fake_path):\n",
    "                    fake_count = len([f for f in os.listdir(fake_path) \n",
    "                                     if os.path.isfile(os.path.join(fake_path, f))])\n",
    "                \n",
    "                # Store results for this split\n",
    "                dataset_results[split] = {\n",
    "                    \"real\": real_count,\n",
    "                    \"fake\": fake_count,\n",
    "                    \"total\": real_count + fake_count\n",
    "                }\n",
    "                \n",
    "                dataset_real += real_count\n",
    "                dataset_fake += fake_count\n",
    "                \n",
    "                print(f\"  {split.upper()} Split: Real: {real_count}, Fake: {fake_count}, Total: {real_count + fake_count}\")\n",
    "            \n",
    "            # Store dataset totals\n",
    "            all_results[category][dataset] = {\n",
    "                \"real\": dataset_real,\n",
    "                \"fake\": dataset_fake,\n",
    "                \"total\": dataset_real + dataset_fake,\n",
    "                \"splits\": dataset_results\n",
    "            }\n",
    "            \n",
    "            # Print dataset totals\n",
    "            print(f\"\\nTOTALS FOR DATASET {full_name}:\")\n",
    "            print(f\"  Real images (0): {dataset_real}\")\n",
    "            print(f\"  Fake images (1): {dataset_fake}\")\n",
    "            print(f\"  Total images: {dataset_real + dataset_fake}\")\n",
    "            print(f\"  Processing time: {time.time() - dataset_start_time:.2f} seconds\")\n",
    "            \n",
    "            category_real += dataset_real\n",
    "            category_fake += dataset_fake\n",
    "        \n",
    "        # Category totals\n",
    "        print(f\"\\n{'-'*60}\")\n",
    "        print(f\"TOTALS FOR CATEGORY: {category}\")\n",
    "        print(f\"  Real images (0): {category_real}\")\n",
    "        print(f\"  Fake images (1): {category_fake}\")\n",
    "        print(f\"  Total images: {category_real + category_fake}\")\n",
    "        print(f\"{'-'*60}\")\n",
    "        \n",
    "        grand_total_real += category_real\n",
    "        grand_total_fake += category_fake\n",
    "    \n",
    "    # Print grand totals\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"GRAND TOTALS ACROSS ALL DATASETS\")\n",
    "    print(f\"Total real images (0): {grand_total_real}\")\n",
    "    print(f\"Total fake images (1): {grand_total_fake}\")\n",
    "    print(f\"Total images: {grand_total_real + grand_total_fake}\")\n",
    "    print(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Run the nested dataset analysis\n",
    "all_results = analyze_nested_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9412d7",
   "metadata": {},
   "source": [
    "## Nested Dataset Structure Analysis\n",
    "\n",
    "This enhanced function handles the hierarchical dataset structure:\n",
    "\n",
    "```\n",
    "dataset/\n",
    "├── Diffusion/\n",
    "│   ├── FLUX1_256/\n",
    "│   └── StableDiffusion_256/\n",
    "├── GAN/\n",
    "│   ├── StarGAN_128/\n",
    "│   ├── StyleGAN_256/\n",
    "│   └── StyleGAN2_256/\n",
    "└── Handcrafted/\n",
    "    └── DEFACTO_256/\n",
    "```\n",
    "\n",
    "Key improvements:\n",
    "1. **Multi-level traversal**: Handles nested directories by category then dataset\n",
    "2. **Optimized scanning**: Eliminates redundant file system calls\n",
    "3. **Performance monitoring**: Tracks execution time at dataset and overall level\n",
    "4. **Structured results**: Stores data in a nested dictionary for potential visualization\n",
    "5. **Flexible split naming**: Handles both \"val\" and \"validation\" directory names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad11c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage and visualization\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    has_visualization_libs = True\n",
    "except ImportError:\n",
    "    has_visualization_libs = False\n",
    "    print(\"Note: For visualization, install pandas and matplotlib using:\")\n",
    "    print(\"pip install pandas matplotlib\")\n",
    "\n",
    "def visualize_dataset_stats(results):\n",
    "    \"\"\"Create visualization of dataset statistics\"\"\"\n",
    "    if not has_visualization_libs:\n",
    "        print(\"Visualization libraries not available. Install pandas and matplotlib.\")\n",
    "        return\n",
    "    \n",
    "    # Prepare data for visualization\n",
    "    data = []\n",
    "    \n",
    "    # Convert nested dictionary to flat list for DataFrame\n",
    "    for category, datasets in results.items():\n",
    "        for dataset, stats in datasets.items():\n",
    "            data.append({\n",
    "                'Category': category,\n",
    "                'Dataset': dataset,\n",
    "                'Real Images': stats['real'],\n",
    "                'Fake Images': stats['fake'],\n",
    "                'Total Images': stats['total'],\n",
    "                'Real/Fake Ratio': stats['real'] / stats['fake'] if stats['fake'] > 0 else float('inf')\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Plot total images by dataset\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Group by category, then sort by total images\n",
    "    df = df.sort_values(['Category', 'Total Images'], ascending=[True, False])\n",
    "    \n",
    "    # Create bar chart\n",
    "    ax = plt.subplot(111)\n",
    "    bar_width = 0.35\n",
    "    index = range(len(df))\n",
    "    \n",
    "    # Plot bars\n",
    "    real_bars = ax.bar(index, df['Real Images'], bar_width, label='Real Images', color='green')\n",
    "    fake_bars = ax.bar([i + bar_width for i in index], df['Fake Images'], bar_width, label='Fake Images', color='red')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Dataset')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title('Real vs. Fake Image Distribution Across Datasets')\n",
    "    plt.xticks([i + bar_width/2 for i in index], [f\"{cat}/{ds}\" for cat, ds in zip(df['Category'], df['Dataset'])], rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\nDATASET SUMMARY TABLE:\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Category summary\n",
    "    print(\"\\nCATEGORY SUMMARY:\")\n",
    "    category_summary = df.groupby('Category').sum()[['Real Images', 'Fake Images', 'Total Images']]\n",
    "    category_summary['Real/Fake Ratio'] = category_summary['Real Images'] / category_summary['Fake Images']\n",
    "    print(category_summary)\n",
    "    \n",
    "    plt.show()\n",
    "    return df\n",
    "\n",
    "# Run the analysis and visualize the results\n",
    "# Uncomment the lines below to run\n",
    "# all_results = analyze_nested_datasets()\n",
    "# df_stats = visualize_dataset_stats(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3990f1",
   "metadata": {},
   "source": [
    "## Running the Analysis\n",
    "\n",
    "To analyze your dataset structure and visualize the results:\n",
    "\n",
    "1. Run the cell below to execute the analysis on your nested directory structure\n",
    "2. The function will print detailed information about each dataset\n",
    "3. A visualization will show the distribution of real vs. fake images across all datasets\n",
    "4. Summary statistics will be displayed in tabular format\n",
    "\n",
    "This will help you understand the balance of your dataset, which is important for training machine learning models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
